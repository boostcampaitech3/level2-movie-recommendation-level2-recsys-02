{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8e0eeb-5c8c-4abb-995f-1455a395f56a",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c99d080-f3b0-41aa-941c-c810baa7270c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "## 각종 파라미터 세팅\n",
    "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
    "\n",
    "\n",
    "parser.add_argument('--data', type=str, default='data/train/',\n",
    "                    help='Movielens dataset location')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--wd', type=float, default=0.00,\n",
    "                    help='weight decay coefficient')\n",
    "parser.add_argument('--batch_size', type=int, default=500,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=20,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--total_anneal_steps', type=int, default=200000,\n",
    "                    help='the total number of gradient updates for annealing')\n",
    "parser.add_argument('--anneal_cap', type=float, default=0.2,\n",
    "                    help='largest annealing parameter')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
    "                    help='report interval')\n",
    "parser.add_argument('--save', type=str, default='model.pt',\n",
    "                    help='path to save the final model')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Set the random seed manually for reproductibility.\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4094c2af-0983-4ce8-8a32-cbe8c706b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "\n",
    "    return count\n",
    "\n",
    "# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상) \n",
    "# 데이터만을 추출할 때 사용하는 함수입니다.\n",
    "# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'item')\n",
    "        tp = tp[tp['item'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'user')\n",
    "        tp = tp[tp['user'].isin(usercount.index[usercount >= min_uc])]\n",
    "\n",
    "    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n",
    "    return tp, usercount, itemcount\n",
    "\n",
    "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n",
    "#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n",
    "#확인하기 위함입니다.\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('user')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "    \n",
    "    for _, group in data_grouped_by_user:\n",
    "        n_items_u = len(group)\n",
    "        \n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        \n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "    \n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te\n",
    "\n",
    "def numerize(tp, profile2id, show2id):\n",
    "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
    "    sid = tp['item'].apply(lambda x: show2id[x])\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "867c941f-7ad9-4b16-96e3-6a4d571b5064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and Preprocess Movielens dataset\n",
      "원본 데이터\n",
      "            user   item        time\n",
      "0            11   4643  1230782529\n",
      "1            11    170  1230782534\n",
      "2            11    531  1230782539\n",
      "3            11    616  1230782542\n",
      "4            11   2140  1230782563\n",
      "...         ...    ...         ...\n",
      "5154466  138493  44022  1260209449\n",
      "5154467  138493   4958  1260209482\n",
      "5154468  138493  68319  1260209720\n",
      "5154469  138493  40819  1260209726\n",
      "5154470  138493  27311  1260209807\n",
      "\n",
      "[5154471 rows x 3 columns]\n",
      "5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n",
      "            user   item        time\n",
      "0            11   4643  1230782529\n",
      "1            11    170  1230782534\n",
      "2            11    531  1230782539\n",
      "3            11    616  1230782542\n",
      "4            11   2140  1230782563\n",
      "...         ...    ...         ...\n",
      "5154466  138493  44022  1260209449\n",
      "5154467  138493   4958  1260209482\n",
      "5154468  138493  68319  1260209720\n",
      "5154469  138493  40819  1260209726\n",
      "5154470  138493  27311  1260209807\n",
      "\n",
      "[5154471 rows x 3 columns]\n",
      "유저별 리뷰수\n",
      " user\n",
      "11        376\n",
      "14        180\n",
      "18         77\n",
      "25         91\n",
      "31        154\n",
      "         ... \n",
      "138473     63\n",
      "138475    124\n",
      "138486    137\n",
      "138492     68\n",
      "138493    314\n",
      "Length: 31360, dtype: int64\n",
      "아이템별 리뷰수\n",
      " item\n",
      "1         12217\n",
      "2          3364\n",
      "3           734\n",
      "4            43\n",
      "5           590\n",
      "          ...  \n",
      "118700       54\n",
      "118900       60\n",
      "118997       52\n",
      "119141      122\n",
      "119145       78\n",
      "Length: 6807, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Load and Preprocess Movielens dataset\")\n",
    "# Load Data\n",
    "DATA_DIR = args.data\n",
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n",
    "print(\"원본 데이터\\n\", raw_data)\n",
    "\n",
    "# Filter Data\n",
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n",
    "#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n",
    "print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n",
    "\n",
    "print(\"유저별 리뷰수\\n\",user_activity)\n",
    "print(\"아이템별 리뷰수\\n\",item_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46650610-7018-4d0d-81d8-43baa63e5714",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEFORE) unique_uid: Int64Index([    11,     14,     18,     25,     31,     35,     43,     50,\n",
      "                58,     60,\n",
      "            ...\n",
      "            138459, 138461, 138470, 138471, 138472, 138473, 138475, 138486,\n",
      "            138492, 138493],\n",
      "           dtype='int64', name='user', length=31360)\n",
      "(AFTER) unique_uid: Int64Index([ 27968,  67764,   2581,  82969, 137831,  48639,  97870,  40424,\n",
      "             46835,  79570,\n",
      "            ...\n",
      "            114284,   9009,  21165,  33920,  22054, 135379, 125855,  41891,\n",
      "             15720,  17029],\n",
      "           dtype='int64', name='user', length=31360)\n",
      "훈련 데이터에 사용될 사용자 수: 31360\n",
      "검증 데이터에 사용될 사용자 수: 0\n"
     ]
    }
   ],
   "source": [
    "# Shuffle User Indices\n",
    "unique_uid = user_activity.index\n",
    "print(\"(BEFORE) unique_uid:\",unique_uid)\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "print(\"(AFTER) unique_uid:\",unique_uid)\n",
    "\n",
    "n_users = unique_uid.size #31360\n",
    "n_heldout_users = 0\n",
    "\n",
    "tr_users = unique_uid\n",
    "# Split Train/Validation/Test User Indices\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2):]\n",
    "# te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "\n",
    "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
    "print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n",
    "print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n",
    "# print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570523a4-d78c-4237-96ec-a2ae39269052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    '''\n",
    "    Load Movielens dataset\n",
    "    '''\n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
    "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
    "\n",
    "        self.n_items = self.load_n_items()\n",
    "    \n",
    "    def load_data(self, datatype='train'):\n",
    "        if datatype == 'train':\n",
    "            return self._load_train_data()\n",
    "        elif datatype == 'validation':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        elif datatype == 'test':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        else:\n",
    "            raise ValueError(\"datatype should be in [train, validation, test]\")\n",
    "        \n",
    "    def load_n_items(self):\n",
    "        unique_sid = list()\n",
    "        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                unique_sid.append(line.strip())\n",
    "        n_items = len(unique_sid)\n",
    "        return n_items\n",
    "    \n",
    "    def _load_train_data(self):\n",
    "        path = os.path.join(self.pro_dir, 'train.csv')\n",
    "        \n",
    "        tp = pd.read_csv(path)\n",
    "        n_users = tp['uid'].max() + 1\n",
    "\n",
    "        rows, cols = tp['uid'], tp['sid']\n",
    "        data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                                 (rows, cols)), dtype='float64',\n",
    "                                 shape=(n_users, self.n_items))\n",
    "        return data\n",
    "    \n",
    "    def _load_tr_te_data(self, datatype='test'):\n",
    "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
    "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
    "\n",
    "        tp_tr = pd.read_csv(tr_path)\n",
    "        tp_te = pd.read_csv(te_path)\n",
    "\n",
    "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        return data_tr, data_te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05387d93-4feb-4792-9d03-9a8ebe39536a",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c9a793f-59ac-4741-a12e-a363f492e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class MultiDAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-DAE.\n",
    "\n",
    "    Multi-DAE : Denoising Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
    "        super(MultiDAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims:\n",
    "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        else:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.dims[:-1], self.dims[1:])])\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "\n",
    "\n",
    "\n",
    "class MultiVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Container module for Multi-VAE.\n",
    "\n",
    "    Multi-VAE : Variational Autoencoder with Multinomial Likelihood\n",
    "    See Variational Autoencoders for Collaborative Filtering\n",
    "    https://arxiv.org/abs/1802.05814\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p_dims, q_dims=None, dropout=0.5):\n",
    "        super(MultiVAE, self).__init__()\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims:\n",
    "            assert q_dims[0] == p_dims[-1], \"In and Out dimensions must equal to each other\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q- network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        else:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "\n",
    "        # Last dimension of q- network is for mean and variance\n",
    "        temp_q_dims = self.q_dims[:-1] + [self.q_dims[-1] * 2]\n",
    "        self.q_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(temp_q_dims[:-1], temp_q_dims[1:])])\n",
    "        self.p_layers = nn.ModuleList([nn.Linear(d_in, d_out) for\n",
    "            d_in, d_out in zip(self.p_dims[:-1], self.p_dims[1:])])\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        mu, logvar = self.encode(input)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def encode(self, input):\n",
    "        h = F.normalize(input)\n",
    "        h = self.drop(h)\n",
    "        \n",
    "        for i, layer in enumerate(self.q_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.q_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "            else:\n",
    "                mu = h[:, :self.q_dims[-1]]\n",
    "                logvar = h[:, self.q_dims[-1]:]\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = z\n",
    "        for i, layer in enumerate(self.p_layers):\n",
    "            h = layer(h)\n",
    "            if i != len(self.p_layers) - 1:\n",
    "                h = F.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def init_weights(self):\n",
    "        for layer in self.q_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "        \n",
    "        for layer in self.p_layers:\n",
    "            # Xavier Initialization for weights\n",
    "            size = layer.weight.size()\n",
    "            fan_out = size[0]\n",
    "            fan_in = size[1]\n",
    "            std = np.sqrt(2.0/(fan_in + fan_out))\n",
    "            layer.weight.data.normal_(0.0, std)\n",
    "\n",
    "            # Normal Initialization for Biases\n",
    "            layer.bias.data.normal_(0.0, 0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_function_vae(recon_x, x, mu, logvar, anneal=1.0):\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1))\n",
    "\n",
    "    return BCE + anneal * KLD\n",
    "\n",
    "def loss_function_dae(recon_x, x):\n",
    "    BCE = -torch.mean(torch.sum(F.log_softmax(recon_x, 1) * x, -1))\n",
    "    return BCE\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3665a93d-4ee6-413b-835b-2d52fdfdcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse2torch_sparse(data):\n",
    "    \"\"\"\n",
    "    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n",
    "    This is much faster than naive use of torch.FloatTensor(data.toarray())\n",
    "    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n",
    "    \"\"\"\n",
    "    samples = data.shape[0]\n",
    "    features = data.shape[1]\n",
    "    coo_data = data.tocoo()\n",
    "    indices = torch.LongTensor([coo_data.row, coo_data.col])\n",
    "    row_norms_inv = 1 / np.sqrt(data.sum(1))\n",
    "    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n",
    "    values = np.array([row2val[r] for r in coo_data.row])\n",
    "    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n",
    "    return t\n",
    "\n",
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e9b67b-e202-41af-96fb-914173804b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(args.data)\n",
    "\n",
    "n_items = loader.load_n_items()\n",
    "train_data = loader.load_data('train')\n",
    "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360680b-05c6-471a-b105-1efb77de0aa9",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dc943cc-dc8c-48a9-9edb-3784399b5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0767036b-0b4c-446f-82d1-5ce45eedf36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi VAE\n",
    "with open('vae_adamW1000.pt', 'rb') as f:\n",
    "    model1 = torch.load(f)\n",
    "    \n",
    "with open('vae_1000.pt', 'rb') as f:\n",
    "    model2 = torch.load(f)\n",
    "    \n",
    "with open('vae_adamW1000drop1.pt', 'rb') as f:\n",
    "    model3 = torch.load(f)\n",
    "    \n",
    "with open('vae_adamW1000drop3.pt', 'rb') as f:\n",
    "    model4 = torch.load(f)\n",
    "    \n",
    "with open('vae_adamW1000drop7.pt', 'rb') as f:\n",
    "    model5 = torch.load(f)\n",
    "    \n",
    "with open('vae_adamW1000drop9.pt', 'rb') as f:\n",
    "    model6 = torch.load(f)\n",
    "    \n",
    "with open('vae_recall.pt', 'rb') as f:\n",
    "    model7 = torch.load(f)\n",
    "# DAE\n",
    "with open('dae_200.pt', 'rb') as f:\n",
    "    model7 = torch.load(f)\n",
    "\n",
    "with open('dae_200drop1.pt', 'rb') as f:\n",
    "    model8 = torch.load(f)\n",
    "   \n",
    "with open('dae_200drop3.pt', 'rb') as f:\n",
    "    model9 = torch.load(f)\n",
    "   \n",
    "with open('dae_200drop7.pt', 'rb') as f:\n",
    "    model10 = torch.load(f)\n",
    "   \n",
    "with open('dae_200drop9.pt', 'rb') as f:\n",
    "    model11 = torch.load(f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e187eed-1456-4445-8126-bc2cb524917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = naive_sparse2tensor(train_data).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af421d03-e27b-4b50-8dc5-3049efa3b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()\n",
    "model4.eval()\n",
    "model5.eval()\n",
    "model6.eval()\n",
    "model7.eval()\n",
    "model8.eval()\n",
    "model9.eval()\n",
    "model10.eval()\n",
    "model11.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    result1 = model1(x)[0]\n",
    "    result2 = model2(x)[0]\n",
    "    result3 = model3(x)[0]\n",
    "    result4 = model4(x)[0]\n",
    "    result5 = model5(x)[0]\n",
    "    result6 = model6(x)[0]\n",
    "    result7 = model7(x)[0]\n",
    "    result8 = model8(x)\n",
    "    result9 = model9(x)\n",
    "    result10 = model10(x)\n",
    "    result11 = model11(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c645026-b72c-4527-83a5-96cf282eab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31360, 6807])\n",
      "torch.Size([31360, 6807])\n",
      "torch.Size([31360, 6807])\n",
      "torch.Size([31360, 6807])\n",
      "torch.Size([31360, 6807])\n",
      "torch.Size([31360, 6807])\n",
      "torch.Size([31360, 6807])\n"
     ]
    }
   ],
   "source": [
    "print(result1.shape)\n",
    "print(result2.shape)\n",
    "print(result3.shape)\n",
    "print(result4.shape)\n",
    "print(result5.shape)\n",
    "print(result6.shape)\n",
    "print(result7.shape)\n",
    "print(result8.shape)\n",
    "print(result9.shape)\n",
    "print(result10.shape)\n",
    "print(result11.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd8495",
   "metadata": {},
   "source": [
    "# output 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e82fdcf7-ee5c-482f-8aa8-4c621951e460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7910, 0.7551, 0.7706,  ..., 0.7046, 0.5837, 0.5908],\n",
       "        [0.8467, 0.8224, 0.8079,  ..., 0.7061, 0.7035, 0.6650],\n",
       "        [0.8427, 0.8135, 0.8207,  ..., 0.7237, 0.7062, 0.6394],\n",
       "        ...,\n",
       "        [0.8078, 0.8179, 0.7771,  ..., 0.6717, 0.5504, 0.6610],\n",
       "        [0.7908, 0.7800, 0.8185,  ..., 0.6929, 0.5745, 0.6440],\n",
       "        [0.7696, 0.8106, 0.8512,  ..., 0.7201, 0.5696, 0.5377]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result1.min(), result1.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result1 = (result1 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54feef80-80c7-4e1b-a103-fedfd758b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6798, 0.6535, 0.6778,  ..., 0.5371, 0.2648, 0.3229],\n",
       "        [0.8053, 0.7918, 0.7567,  ..., 0.5725, 0.5999, 0.5601],\n",
       "        [0.7701, 0.7755, 0.7608,  ..., 0.6799, 0.5367, 0.3841],\n",
       "        ...,\n",
       "        [0.6537, 0.6936, 0.6717,  ..., 0.3450, 0.3216, 0.6149],\n",
       "        [0.6609, 0.6460, 0.7198,  ..., 0.3853, 0.2826, 0.4845],\n",
       "        [0.6189, 0.6902, 0.8163,  ..., 0.4951, 0.3547, 0.3612]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result2.min(), result2.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result2 = (result2 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fa2e10f-aaed-43a2-893e-f3e4ca4f3922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7782, 0.7516, 0.7483,  ..., 0.7594, 0.5533, 0.5695],\n",
       "        [0.8060, 0.7887, 0.7649,  ..., 0.7152, 0.7201, 0.6253],\n",
       "        [0.7648, 0.8112, 0.7748,  ..., 0.7366, 0.6736, 0.5640],\n",
       "        ...,\n",
       "        [0.7873, 0.8049, 0.7671,  ..., 0.6996, 0.5901, 0.8081],\n",
       "        [0.8076, 0.8245, 0.8416,  ..., 0.7532, 0.6884, 0.7444],\n",
       "        [0.7606, 0.7442, 0.8321,  ..., 0.7015, 0.6090, 0.5995]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result3.min(), result3.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result3 = (result3 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "448a4022-7c4c-40af-96ca-1b85a2622217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7308, 0.7021, 0.7305,  ..., 0.6473, 0.5230, 0.5266],\n",
       "        [0.8360, 0.8451, 0.7881,  ..., 0.6751, 0.7219, 0.5953],\n",
       "        [0.8138, 0.8162, 0.8129,  ..., 0.7134, 0.6735, 0.5586],\n",
       "        ...,\n",
       "        [0.7784, 0.7871, 0.7693,  ..., 0.6528, 0.5909, 0.7060],\n",
       "        [0.7790, 0.7457, 0.8139,  ..., 0.7289, 0.6071, 0.6409],\n",
       "        [0.7406, 0.7608, 0.8540,  ..., 0.6894, 0.5778, 0.5290]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result4.min(), result4.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result4 = (result4 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32f0420f-8827-4353-9208-fcb8635bbf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7358, 0.7258, 0.7312,  ..., 0.6614, 0.5040, 0.4604],\n",
       "        [0.8269, 0.8038, 0.7962,  ..., 0.6633, 0.7242, 0.6226],\n",
       "        [0.7836, 0.7989, 0.7900,  ..., 0.6897, 0.6792, 0.5043],\n",
       "        ...,\n",
       "        [0.7401, 0.7412, 0.7376,  ..., 0.5724, 0.5102, 0.6985],\n",
       "        [0.7284, 0.7292, 0.7758,  ..., 0.5283, 0.4907, 0.6115],\n",
       "        [0.7198, 0.7670, 0.8314,  ..., 0.6188, 0.5854, 0.4937]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result5.min(), result5.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result5 = (result5 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b90a30c-c839-4daa-9709-0d5f3a0cfef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6791, 0.6888, 0.7233,  ..., 0.4972, 0.2939, 0.3071],\n",
       "        [0.7846, 0.8123, 0.7337,  ..., 0.6083, 0.6679, 0.5012],\n",
       "        [0.7541, 0.8050, 0.7790,  ..., 0.6160, 0.5581, 0.4460],\n",
       "        ...,\n",
       "        [0.6726, 0.7423, 0.6645,  ..., 0.5035, 0.4056, 0.6071],\n",
       "        [0.6723, 0.6883, 0.7396,  ..., 0.4781, 0.4146, 0.5234],\n",
       "        [0.6757, 0.7140, 0.8499,  ..., 0.5322, 0.5213, 0.5190]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result6.min(), result6.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result6 = (result6 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "594c161b-b9b5-47d6-8b10-cc639307aeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7426, 0.7408, 0.7405,  ..., 0.6508, 0.4493, 0.5023],\n",
       "        [0.8357, 0.8178, 0.7856,  ..., 0.7047, 0.7072, 0.6083],\n",
       "        [0.7881, 0.7897, 0.7764,  ..., 0.7325, 0.6273, 0.5341],\n",
       "        ...,\n",
       "        [0.7194, 0.7621, 0.7782,  ..., 0.6867, 0.5889, 0.7020],\n",
       "        [0.7421, 0.7395, 0.8040,  ..., 0.6485, 0.5620, 0.5680],\n",
       "        [0.7266, 0.7603, 0.8437,  ..., 0.7287, 0.5075, 0.5316]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result7.min(), result7.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result7 = (result7 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2396bdc-7bd0-4813-94c2-09c785033569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5174, 0.5233, 0.5277,  ..., 0.4878, 0.2163, 0.3043],\n",
       "        [0.7271, 0.6403, 0.6408,  ..., 0.5180, 0.5048, 0.3221],\n",
       "        [0.6214, 0.6303, 0.5800,  ..., 0.4588, 0.4804, 0.2725],\n",
       "        ...,\n",
       "        [0.5285, 0.5674, 0.6016,  ..., 0.3661, 0.2225, 0.4797],\n",
       "        [0.4962, 0.4425, 0.4812,  ..., 0.3456, 0.2679, 0.3384],\n",
       "        [0.4916, 0.5581, 0.6838,  ..., 0.3574, 0.2765, 0.2702]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result8.min(), result8.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result8 = (result8 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3b883e3-5028-4093-9988-b867bc078578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5804, 0.5328, 0.5659,  ..., 0.4702, 0.3303, 0.2837],\n",
       "        [0.7012, 0.6692, 0.6575,  ..., 0.4621, 0.4729, 0.4200],\n",
       "        [0.6473, 0.7465, 0.7072,  ..., 0.5101, 0.5630, 0.3991],\n",
       "        ...,\n",
       "        [0.5895, 0.5926, 0.5979,  ..., 0.5561, 0.2957, 0.5078],\n",
       "        [0.5660, 0.4532, 0.6307,  ..., 0.3474, 0.2875, 0.4228],\n",
       "        [0.5445, 0.6152, 0.7248,  ..., 0.4918, 0.3212, 0.3037]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result9.min(), result9.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result9 = (result9 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19df884c-698b-4aca-8fde-6c60abeaf3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5967, 0.5726, 0.5712,  ..., 0.4994, 0.2789, 0.2163],\n",
       "        [0.7272, 0.7175, 0.6604,  ..., 0.5550, 0.5762, 0.4719],\n",
       "        [0.6609, 0.6638, 0.6423,  ..., 0.5675, 0.4998, 0.2913],\n",
       "        ...,\n",
       "        [0.5112, 0.6484, 0.5624,  ..., 0.4025, 0.3289, 0.4473],\n",
       "        [0.5577, 0.5479, 0.6242,  ..., 0.4080, 0.2303, 0.3395],\n",
       "        [0.5230, 0.5768, 0.7345,  ..., 0.4962, 0.3706, 0.2604]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result10.min(), result10.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result10 = (result10 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca311df5-3d68-4e8b-b2c7-c8b4007ffa51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6076, 0.5683, 0.5926,  ..., 0.4253, 0.2755, 0.2345],\n",
       "        [0.7380, 0.7303, 0.6682,  ..., 0.5544, 0.6255, 0.4841],\n",
       "        [0.6859, 0.6823, 0.6608,  ..., 0.4962, 0.4859, 0.3407],\n",
       "        ...,\n",
       "        [0.6187, 0.6543, 0.6092,  ..., 0.2284, 0.3425, 0.5767],\n",
       "        [0.5329, 0.5672, 0.6721,  ..., 0.3893, 0.2466, 0.3429],\n",
       "        [0.5335, 0.6228, 0.7472,  ..., 0.4779, 0.3031, 0.3229]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_min, v_max = result11.min(), result11.max()\n",
    "new_min, new_max = 0,1\n",
    "# scaling된 vector\n",
    "result11 = (result11 - v_min)/(v_max - v_min)*(new_max - new_min) + new_min\n",
    "result11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57283050-7918-4323-96f7-2a03f7dea831",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result1 + result2 + result3 + result4 +result5 + result6 +result7 + result8 + result9 + result10 +result11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17d4a046-c139-4783-97c9-0c0b0ad2f270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.3591, 4.2660, 4.3738,  ..., 3.6984, 2.6188, 2.7101],\n",
       "        [4.9352, 4.8932, 4.6682,  ..., 3.9300, 4.1247, 3.5525],\n",
       "        [4.7524, 4.7987, 4.7398,  ..., 4.1552, 3.7809, 3.0665],\n",
       "        ...,\n",
       "        [4.3719, 4.5442, 4.3983,  ..., 3.4321, 2.9676, 3.9895],\n",
       "        [4.3735, 4.3289, 4.6716,  ..., 3.4621, 2.9315, 3.4723],\n",
       "        [4.2512, 4.5028, 5.0465,  ..., 3.7843, 3.1164, 2.9722]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aaf683f7-5070-45c3-8f68-0bf5b979f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "torch.save(result, 'result.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86a743e6-a38c-4417-95f9-6261ce6f6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 user-item matrix 불러오기\n",
    "import torch\n",
    "result1 = torch.load('result.pt')\n",
    "result2 = torch.load('pby_result.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7486c23b-63b7-48f7-8c09-e58a8f04873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show2id = dict((i,sid) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((i,pid) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc891718-8ab4-4798-af22-c05488e04ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf04dec8c1274d23910c5c83a39dee69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=31360.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "j = result - x * 200\n",
    "n = j.sort()[1][:,-10:]\n",
    "from tqdm.notebook import tqdm\n",
    "sub_u, sub_i = [], []\n",
    "for target_u in tqdm(range(0, 31360)) :\n",
    "    target_i = n[target_u]\n",
    "    for target in target_i:\n",
    "        sub_u.append(profile2id[target_u])\n",
    "        sub_i.append(show2id[int(target)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2df9068e-2c27-47e8-9ab3-8c261ff1d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "sub_u, sub_i = [], []\n",
    "for target_u in tqdm(range(0, 31360)) :\n",
    "    target_i = n[target_u]\n",
    "    for target in target_i:\n",
    "        sub_u.append(profile2id[target_u])\n",
    "        sub_i.append(show2id[int(target)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c5d624c-b884-4e5f-b05c-98bf1edf6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = {\"user\" : sub_u, \"item\" : sub_i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b882503a-f020-4d48-9616-d2db9deeeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(submission)\n",
    "submission_df = submission_df.sort_values('user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0ad55acd-5b55-4fde-8bae-0b8c40297c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission_last.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fd3ca-aa9e-41b2-8727-a58128590802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
