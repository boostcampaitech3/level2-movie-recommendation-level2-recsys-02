{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import dok_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/movie-recommendation/data/train/'\n",
    "data = pd.read_csv(data_dir + 'train_ratings.csv')\n",
    "data = data[['user', 'item']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group_dfs = data.groupby(by='user')['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31360/31360 [01:41<00:00, 309.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dfs = []\n",
    "test_dfs  = []\n",
    "\n",
    "items = set(data.loc[:, 'item'])\n",
    "\n",
    "for u, u_items in tqdm(user_group_dfs):\n",
    "    num_data = len(u_items)\n",
    "    num_test = int(num_data*0.2)\n",
    "\n",
    "    train_idx = np.random.choice(num_data, num_data-num_test, replace=False)\n",
    "    test_idx = [idx for idx in range(num_data) if idx not in train_idx]\n",
    "\n",
    "    train_df = pd.DataFrame({'user':[u]*len(train_idx), 'item':u_items.values[train_idx]})\n",
    "    test_df = pd.DataFrame({'user':[u]*len(test_idx), 'item':u_items.values[test_idx], 'rating': [1]*len(test_idx)})\n",
    "\n",
    "    num_negs = len(test_idx)*2 if len(test_idx) >= 10 else 10\n",
    "    neg_items = np.random.choice(list(items - set(u_items)), num_negs, replace=False)\n",
    "    neg_df = pd.DataFrame({'user': [u]*num_negs, 'item': neg_items, 'rating': [0]*num_negs})\n",
    "\n",
    "    train_dfs.append(train_df)\n",
    "    test_dfs.extend([test_df, neg_df])\n",
    "\n",
    "train_df = pd.concat(train_dfs)\n",
    "test_df = pd.concat(test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/movie-recommendation/data/train/bpr/'\n",
    "train_df.to_csv(data_dir+'train.csv')\n",
    "test_df.to_csv(data_dir+'valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_dir+'train.csv')\n",
    "valid_df = pd.read_csv(data_dir+'valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRDataset(Dataset):\n",
    "\tdef __init__(self, data_path, num_negative=5, is_training=True, train_matrix=None):\n",
    "\t\tsuper(BPRDataset, self).__init__()\n",
    "\t\t\n",
    "\t\tself.data = pd.read_csv(data_path)\n",
    "\n",
    "\t\tif is_training :\n",
    "\t\t\tself.data = self.data[['user', 'item']].sort_values(by=['user'])\n",
    "\t\telse :\n",
    "\t\t\tself.data = self.data[['user', 'item', 'rating']].sort_values(by=['user'])\n",
    "\t\t\n",
    "\t\tself.train_matrix = train_matrix\n",
    "\n",
    "\t\tself.zero_based_mapping()\n",
    "\t\tif self.train_matrix == None:\n",
    "\t\t\tself.get_sparse_matrix()\n",
    "\n",
    "\t\tself.num_negative = num_negative\n",
    "\t\tself.is_training = is_training\n",
    "\t\tself.features = self.data.values\n",
    "\n",
    "\tdef negative_sampling(self):\n",
    "\t\tassert self.is_training, 'no need to sampling when testing'\n",
    "\n",
    "\t\tnegative_samples = []\n",
    "\t\t\n",
    "\t\tfor u, i in tqdm(self.data.values):\n",
    "\t\t\tfor _ in range(self.num_negative):\n",
    "\t\t\t\tj = np.random.randint(self.n_item)\n",
    "\t\t\t\twhile (u, j) in self.train_matrix:\n",
    "\t\t\t\t\tj = np.random.randint(self.n_item)\n",
    "\t\t\t\tnegative_samples.append([u, i, j])\n",
    "\t\t\n",
    "\t\tself.features = negative_samples\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn self.num_negative * len(self.data) if \\\n",
    "\t\t\t\tself.is_training else len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tuser = self.features[idx][0]\n",
    "\t\titem_i = self.features[idx][1]\n",
    "\t\titem_j = self.features[idx][2] if \\\n",
    "\t\t\t\tself.is_training else self.features[idx][1]\n",
    "\t\treturn user, item_i, item_j \n",
    "\t\n",
    "\tdef zero_based_mapping(self) :\n",
    "\t\tusers = list(set(self.data.loc[:,'user']))\n",
    "\t\titems =  list(set(self.data.loc[:, 'item']))\n",
    "\n",
    "\t\tself.n_user = len(users)\n",
    "\t\tself.n_item = len(items)\n",
    "\n",
    "\t\t# user, item을 zero-based index로 mapping\n",
    "\t\tif self.n_user-1 != max(users):\n",
    "\t\t\tusers_dict = {users[i]: i for i in range(len(users))}\n",
    "\t\t\tself.data['user']  = self.data['user'].map(lambda x : users_dict[x])\n",
    "\n",
    "\t\tif self.n_item-1 != max(items):\n",
    "\t\t\titems_dict = {items[i]: i for i in range(len(items))}\n",
    "\t\t\tself.data['item']  = self.data['item'].map(lambda x : items_dict[x])\n",
    "\t\n",
    "\tdef get_sparse_matrix(self):\n",
    "\t\ttrain_matrix = dok_matrix((self.n_user, self.n_item), dtype=np.float32)\n",
    "\t\tfor u, i in tqdm(self.data.values):\n",
    "\t\t\ttrain_matrix[u, i] = 1.0\n",
    "\t\tself.train_matrix = train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(nn.Module):\n",
    "\tdef __init__(self, user_num, item_num, factor_num):\n",
    "\t\tsuper(BPR, self).__init__()\n",
    "\t\t\"\"\"\n",
    "\t\tuser_num: number of users;\n",
    "\t\titem_num: number of items;\n",
    "\t\tfactor_num: number of predictive factors.\n",
    "\t\t\"\"\"\t\t\n",
    "\t\tself.embed_user = nn.Embedding(user_num, factor_num)\n",
    "\t\tself.embed_item = nn.Embedding(item_num, factor_num)\n",
    "\n",
    "\t\tnn.init.normal_(self.embed_user.weight, std=0.01)\n",
    "\t\tnn.init.normal_(self.embed_item.weight, std=0.01)\n",
    "\n",
    "\tdef forward(self, user, item_i, item_j):\n",
    "\t\tuser = self.embed_user(user)\n",
    "\t\titem_i = self.embed_item(item_i)\n",
    "\t\titem_j = self.embed_item(item_j)\n",
    "\n",
    "\t\tprediction_i = (user * item_i).sum(dim=-1)\n",
    "\t\tprediction_j = (user * item_j).sum(dim=-1)\n",
    "\t\treturn prediction_i, prediction_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4136075/4136075 [00:47<00:00, 87190.27it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/opt/ml/movie-recommendation/data/train/bpr/'\n",
    "train_dataset = BPRDataset(data_dir + 'train.csv')\n",
    "valid_dataset = BPRDataset(data_dir + 'valid.csv', is_training=False, train_matrix=train_dataset.train_matrix, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BPR(train_dataset.n_user, train_dataset.n_item, 7).to(device)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True, num_workers=4)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False, num_workers=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(actual, predicted, topk):\n",
    "    sum_recall = 0.0\n",
    "    num_users = len(predicted)\n",
    "    true_users = 0\n",
    "    for i in range(num_users):\n",
    "        act_set = set(actual[i])\n",
    "        pred_set = set(predicted[i][:topk])\n",
    "        if len(act_set) != 0:\n",
    "            sum_recall += len(act_set & pred_set) / float(len(act_set))\n",
    "            true_users += 1\n",
    "    return sum_recall / true_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17522156432571986\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "\tmodel.train() \n",
    "\ttrain_loader.dataset.negative_sampling()\n",
    "\n",
    "\tfor user, item_i, item_j in train_loader:\n",
    "\t\tuser = user.to(device)\n",
    "\t\titem_i = item_i.to(device)\n",
    "\t\titem_j = item_j.to(device)\n",
    "\n",
    "\t\tmodel.zero_grad()\n",
    "\t\tprediction_i, prediction_j = model(user, item_i, item_j)\n",
    "\t\tloss =- (prediction_i - prediction_j).sigmoid().log().sum()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\tmodel.eval()\n",
    "\n",
    "\tall_preds = []\n",
    "\n",
    "\tfor user, item_i, item_j in valid_loader:\n",
    "\t\tuser = user.to(device)\n",
    "\t\titem_i = item_i.to(device)\n",
    "\t\titem_j = item_j.to(device)\n",
    "\n",
    "\t\tprediction_i, prediction_j = model(user, item_i, item_j)\n",
    "\t\t\n",
    "\t\tall_preds.append(prediction_i)\n",
    "\t\n",
    "\tall_preds = torch.cat(all_preds).detach().cpu().numpy()\n",
    "\tvalid_dataset.data['preds'] = all_preds\n",
    "\n",
    "\tuser_group_dfs = list(valid_dataset.data.groupby(by='user'))\n",
    "\n",
    "\tpredicted = []\n",
    "\tactual = []\n",
    "\tfor user, user_df in user_group_dfs :\n",
    "\t\trecommends = np.array(user_df.nlargest(10, ['preds'])['item'])\n",
    "\t\tpredicted.append(recommends)\n",
    "\t\tground_truth = np.array(user_df[user_df['rating'] == 1]['item'])\n",
    "\t\tactual.append(ground_truth)\n",
    "\tprint(recall_at_k(actual, predicted, 10))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
