{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from scipy.sparse import dok_matrix\n",
    "import json\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_based_mapping(data) :\n",
    "    with open('/opt/ml/movie-recommendation/data/train/zero_mapping.json', 'r') as f:\n",
    "        dict_data= json.load(f)\n",
    "\n",
    "    data['user']  = data['user'].map(lambda x : dict_data['user'][str(x)])\n",
    "    data['item']  = data['item'].map(lambda x : dict_data['item'][str(x)])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        self.data = pd.read_csv(data_path)\n",
    "\n",
    "        self.data = zero_based_mapping(self.data)\n",
    "        self.attributes = self.get_item_attributes()\n",
    "\n",
    "        self.X = torch.tensor(np.array(self.data.loc[:, ['user', 'item']])).long()\n",
    "        self.y = torch.tensor(np.array(self.data.loc[:, 'rating'])).long()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_i = self.X[index, 1]\n",
    "        X = torch.cat([self.X[index], self.attributes[item_i]])\n",
    "        return X, self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def split_dataset(self, train_ratio=0.9) -> Tuple[Subset, Subset]:\n",
    "        train_size = int(train_ratio * len(self.data))\n",
    "        test_size = len(self.data) - train_size\n",
    "        train_dataset, test_dataset = random_split(self, [train_size, test_size])\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    def get_item_attributes(self):\n",
    "        data_dir = '/opt/ml/movie-recommendation/data/train/'\n",
    "\n",
    "        with open(data_dir+'item2attributes.json', 'r') as f:\n",
    "            item2attributes = json.load(f)\n",
    "\n",
    "        attributes = []\n",
    "\n",
    "        for item in range(6807):    \n",
    "            attribute = [0] * 18\n",
    "            now_attribute = item2attributes[str(item)]\n",
    "            for a in now_attribute[1:]:\n",
    "                attribute[a] = 1\n",
    "            attributes.append([now_attribute[0]]+attribute)\n",
    "        \n",
    "        return torch.tensor(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, field_num, offsets):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "\n",
    "        self.field_num = field_num\n",
    "        self.offsets = torch.tensor(offsets, device='cuda')\n",
    "        self.embedding = nn.Embedding(input_dim+1, embedding_dim, padding_idx=self.offsets[-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        one_hot_x = x[:,:self.field_num-1]\n",
    "        multi_hot_x = x[:,self.field_num-1:].clone()\n",
    "\n",
    "        embed_x = self.embedding(one_hot_x + self.offsets[:-1])\n",
    "\n",
    "        sum_embed = []\n",
    "\n",
    "        indices = multi_hot_x.nonzero()\n",
    "        multi_hot_x[indices[:,0], indices[:,1]] = indices[:,1]+1\n",
    "        embed = self.embedding(multi_hot_x + self.offsets[-1])\n",
    "        sum_embed = torch.sum(embed, axis=1)\n",
    "\n",
    "        embed_x= torch.cat([embed_x, sum_embed.unsqueeze(1)], axis=1)\n",
    "\n",
    "        return embed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, input_dims, embedding_dim):\n",
    "        super(FM, self).__init__()\n",
    "        self.field_num = len(input_dims)\n",
    "        total_input_dim = int(sum(input_dims))\n",
    "        self.offsets = [0]+input_dims[:-1]\n",
    "\n",
    "        self.bias = nn.Parameter(torch.zeros((1,)))\n",
    "        self.fc = EmbeddingLayer(total_input_dim+1, 1, self.field_num, self.offsets)\n",
    "        \n",
    "        self.embedding = EmbeddingLayer(total_input_dim+1, embedding_dim, self.field_num, self.offsets)\n",
    "        self.embedding_dim = self.field_num * embedding_dim\n",
    "\n",
    "    def fm(self, x, embed_x):\n",
    "        fm_y = self.bias + torch.sum(self.fc(x), dim=1)\n",
    "        square_of_sum = torch.sum(embed_x, dim=1) ** 2         \n",
    "        sum_of_square = torch.sum(embed_x ** 2, dim=1)\n",
    "        fm_y += 0.5 * torch.sum(square_of_sum - sum_of_square, dim=1, keepdim=True)\n",
    "        return fm_y\n",
    "\n",
    "    def forward(self, x):\n",
    "        #embedding component\n",
    "        embed_x = self.embedding(x)\n",
    "        #fm component\n",
    "        fm_y = self.fm(x, embed_x).squeeze(1)\n",
    "\n",
    "        y = torch.sigmoid(fm_y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = FMDataset('/opt/ml/movie-recommendation/data/train/fm/Negative Sampled Ratings.csv')\n",
    "\n",
    "train_set, valid_set = dataset.split_dataset()\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_set,\n",
    "    batch_size=1024,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "model = FM(\n",
    "    input_dims=[31360,6807,12,18],\n",
    "    embedding_dim=10\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating validation results... 0/100\n",
      "[Val] accuracy: 76.4695%\n",
      "Calculating validation results... 1/100\n",
      "[Val] accuracy: 81.9613%\n",
      "Calculating validation results... 2/100\n",
      "[Val] accuracy: 84.6191%\n",
      "Calculating validation results... 3/100\n",
      "[Val] accuracy: 85.9275%\n",
      "Calculating validation results... 4/100\n",
      "[Val] accuracy: 86.6377%\n",
      "Calculating validation results... 5/100\n",
      "[Val] accuracy: 87.2488%\n",
      "Calculating validation results... 6/100\n",
      "[Val] accuracy: 87.7996%\n",
      "Calculating validation results... 7/100\n",
      "[Val] accuracy: 88.2393%\n",
      "Calculating validation results... 8/100\n",
      "[Val] accuracy: 88.6426%\n",
      "Calculating validation results... 9/100\n",
      "[Val] accuracy: 88.9504%\n",
      "Calculating validation results... 10/100\n",
      "[Val] accuracy: 89.1771%\n",
      "Calculating validation results... 11/100\n",
      "[Val] accuracy: 89.3829%\n",
      "Calculating validation results... 12/100\n",
      "[Val] accuracy: 89.5556%\n",
      "Calculating validation results... 13/100\n",
      "[Val] accuracy: 89.7112%\n",
      "Calculating validation results... 14/100\n",
      "[Val] accuracy: 89.7971%\n",
      "Calculating validation results... 15/100\n",
      "[Val] accuracy: 89.9109%\n",
      "Calculating validation results... 16/100\n",
      "[Val] accuracy: 89.9815%\n",
      "Calculating validation results... 17/100\n",
      "[Val] accuracy: 90.0659%\n",
      "Calculating validation results... 18/100\n",
      "[Val] accuracy: 90.1016%\n",
      "Calculating validation results... 19/100\n",
      "[Val] accuracy: 90.1761%\n",
      "Calculating validation results... 20/100\n",
      "[Val] accuracy: 90.2157%\n",
      "Calculating validation results... 21/100\n",
      "[Val] accuracy: 90.2325%\n",
      "Calculating validation results... 22/100\n",
      "[Val] accuracy: 90.2613%\n",
      "Calculating validation results... 23/100\n",
      "[Val] accuracy: 90.2912%\n",
      "Calculating validation results... 24/100\n",
      "[Val] accuracy: 90.3277%\n",
      "Calculating validation results... 25/100\n",
      "[Val] accuracy: 90.3470%\n",
      "Calculating validation results... 26/100\n",
      "[Val] accuracy: 90.3668%\n",
      "Calculating validation results... 27/100\n",
      "[Val] accuracy: 90.3824%\n",
      "Calculating validation results... 28/100\n",
      "[Val] accuracy: 90.4102%\n",
      "Calculating validation results... 29/100\n",
      "[Val] accuracy: 90.4317%\n",
      "Calculating validation results... 30/100\n",
      "[Val] accuracy: 90.4355%\n",
      "Calculating validation results... 31/100\n",
      "[Val] accuracy: 90.4787%\n",
      "Calculating validation results... 32/100\n",
      "[Val] accuracy: 90.4575%\n",
      "Calculating validation results... 33/100\n",
      "[Val] accuracy: 90.4916%\n",
      "Calculating validation results... 34/100\n",
      "[Val] accuracy: 90.4851%\n",
      "Calculating validation results... 35/100\n",
      "[Val] accuracy: 90.4842%\n",
      "Calculating validation results... 36/100\n",
      "[Val] accuracy: 90.4977%\n",
      "Calculating validation results... 37/100\n",
      "[Val] accuracy: 90.5007%\n",
      "Calculating validation results... 38/100\n",
      "[Val] accuracy: 90.5276%\n",
      "Calculating validation results... 39/100\n",
      "[Val] accuracy: 90.5429%\n",
      "Calculating validation results... 40/100\n",
      "[Val] accuracy: 90.5315%\n",
      "Calculating validation results... 41/100\n",
      "[Val] accuracy: 90.5200%\n",
      "Calculating validation results... 42/100\n",
      "[Val] accuracy: 90.6036%\n",
      "Calculating validation results... 43/100\n",
      "[Val] accuracy: 90.5605%\n",
      "Calculating validation results... 44/100\n",
      "[Val] accuracy: 90.5541%\n",
      "Calculating validation results... 45/100\n",
      "[Val] accuracy: 90.5815%\n",
      "Calculating validation results... 46/100\n",
      "[Val] accuracy: 90.6012%\n",
      "Calculating validation results... 47/100\n",
      "[Val] accuracy: 90.6195%\n",
      "Calculating validation results... 48/100\n",
      "[Val] accuracy: 90.6020%\n",
      "Calculating validation results... 49/100\n",
      "[Val] accuracy: 90.6038%\n",
      "Calculating validation results... 50/100\n",
      "[Val] accuracy: 90.6015%\n",
      "Calculating validation results... 51/100\n",
      "[Val] accuracy: 90.6243%\n",
      "Calculating validation results... 52/100\n",
      "[Val] accuracy: 90.6420%\n",
      "Calculating validation results... 53/100\n",
      "[Val] accuracy: 90.6213%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/ml/movie-recommendation/notebooks/model/Factorization Machine.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.219.178/opt/ml/movie-recommendation/notebooks/model/Factorization%20Machine.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mtrain() \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.219.178/opt/ml/movie-recommendation/notebooks/model/Factorization%20Machine.ipynb#ch0000010vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m X,y \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B101.101.219.178/opt/ml/movie-recommendation/notebooks/model/Factorization%20Machine.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m \tX \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B101.101.219.178/opt/ml/movie-recommendation/notebooks/model/Factorization%20Machine.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m \ty \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.101.219.178/opt/ml/movie-recommendation/notebooks/model/Factorization%20Machine.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m \tmodel\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\tmodel.train() \n",
    "\n",
    "\tfor X,y in train_loader:\n",
    "\t\tX = X.to(device)\n",
    "\t\ty = y.to(device)\n",
    "\n",
    "\t\tmodel.zero_grad()\n",
    "\t\touts = model(X)\n",
    "\t\tloss = criterion(outs, y.float())\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\n",
    "\tprint(f\"Calculating validation results... {epoch}/{epochs}\")\n",
    "\t\n",
    "\twith torch.no_grad():\n",
    "\t\tmodel.eval()\n",
    "\n",
    "\t\tval_acc_items = []\n",
    "\t\tfor X,y in valid_loader:\n",
    "\t\t\tX = X.to(device)\n",
    "\t\t\ty = y.to(device)\n",
    "\n",
    "\t\t\touts = model(X)\n",
    "\t\t\tpred = torch.round(outs)\n",
    "\n",
    "\t\t\tacc_item = (y == pred).sum().item()\n",
    "\t\t\tval_acc_items.append(acc_item)\n",
    "\t\t\n",
    "\t\tval_acc = np.sum(val_acc_items) / len(valid_set)\n",
    "\n",
    "\tprint(f\"[Val] accuracy: {val_acc:4.4%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(38199, 1, padding_idx=12)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingLayer(\n",
       "  (embedding): Embedding(38199, 10, padding_idx=12)\n",
       ")"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-3.3509], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = train_loader.dataset[0]\n",
    "x=x.to(device)\n",
    "x.view(1,-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_x = model.embedding(x.view(1,-1))\n",
    "fm_y = model.bias + torch.sum(model.fc(x.view(1,-1)), dim=1)\n",
    "square_of_sum = torch.sum(embed_x, dim=1) ** 2         \n",
    "sum_of_square = torch.sum(embed_x ** 2, dim=1)\n",
    "(square_of_sum - sum_of_square).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((square_of_sum - sum_of_square) + fm_y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3ea19d11efa7602c1f12500925a974ed4f31fcf847bd6f694bd5180da2602ded"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
